# 自动化测试框架编写思路

通过读取yaml文件的内容，提取yaml文件中的关键字，根据关键字来对于对应的value进行操作
通过反射机制hasattr，来判断关键字对应什么操作，如variables、validate等

### 自动化和pytest相关内容

#### 怎么修改pytest中的脚本执行顺序

- 默认按照文件名称的排序顺序执行，在文件中按照定义的顺序进行执行的
- 可以使用pytest的插件，pytest-order
- 通过pytest的钩子pytest_collection_modifyitems
- @pytest.mark 标记，并在运行时使用命令行指定某些组的顺序



#### 怎么实现多个脚本同一个预配置

- 通过pytest的钩子pytest_collection_modifyitems
- 使用@pytest.mark 标记，对脚本进行分组



#### fixture怎么实现setup和teardown功能

- yield
- 可以通过 `scope` 参数调整 `fixture` 的生命周期



#### 为什么要自己写一套基于yaml文件的接口测试框架，和公司的框架有什么区别

1. yaml文件编写更简单，但是没有那么灵活，如果加功能可能需要修改框架
2. 公司python脚本的方时更灵活，而且公司框架需要同时支持ui，cli，接口测试
3. 练手，以及学习jenkins docker

#### 什么是fixture

```
fixture 是 pytest 中的一个重要概念，用来为测试提供初始化数据和清理操作。它是一个函数，可以在测试运行前准备必要的资源（如数据库连接、文件、网络连接等），并在测试完成后执行清理操作（如关闭连接、删除临时文件等）。fixture 允许测试函数或类复用这些资源，避免重复的代码，并保证测试的独立性和隔离性。

fixture 的特点
自动管理资源：在测试之前自动创建资源，测试完成后自动销毁资源。
支持共享资源：多个测试用例可以共享同一个 fixture 资源。
灵活性：可以指定作用域、自动清理等功能。
```

#### 怎么修改pytest匹配文件的规则

```
通过在 pytest.ini 文件中添加自定义的 python_files 和 python_functions 配置项，你可以修改 pytest 收集测试的文件和函数匹配模式。
命令行选项 --python-files 和 --python-functions
你还可以通过命令行选项动态修改收集规则：
```

#### 自动化脚本不稳定怎么处理

- 解决环境不稳定：
  - 确保脚本后的teardown会清楚自动化测试过程中所产生的所有数据
  - 使用容器化（如 Docker）或虚拟机来确保测试环境的一致性和隔离性
  - 隔离测试环境：确保每个测试在独立的环境中运行，避免对同一资源的竞争。
- 解决第三方服务或者外部依赖不稳定
  - 对第三方服务进行模拟(Mock)，以避免每次测试时都依赖外部服务。
- 对于webui自动化
  - 修改元素定位，尽量使用相对定位或者使用id/name，避免使用绝对定位
  - 封装一些操作函数，在脚本中使用显式等待，确保页面元素在进行操作之前已经加载完成，避免因页面加载慢而导致的错误。
- 增加失败重试机制(pytest中的retry)
- 在测试步骤中增加详细的操作日志，对于webui自动化可以在失败时，增加一个失败截图
- 对于接口测试，对于响应的校验不要太严格
  - 某些字段的值可能是非固定的（例如订单号、商品 ID、用户 ID 等），但它们的格式或范围是固定的。在这种情况下，你可以使用正则表达式来校验这些值是否符合预期格式
  - 校验时间戳是否为当前时间之前，或者是否符合某个时间范围。
- 对于耗时较长的用例，可以拆分脚本



#### 什么情况适合自动化



#### 自动化测试过程中可能会有一些资源损耗的问题，应该怎么处理，比如支付接口等

```
在自动化测试中，处理资源消耗问题（尤其是像支付接口这样可能涉及到实际费用的服务）时，可以采取以下策略：

使用 Mock 技术：通过模拟支付接口的响应，避免实际调用支付接口。
使用沙箱或测试环境：许多外部服务提供沙箱环境，可以模拟实际操作而不产生费用。
实现限流和重试机制：在多次调用外部服务时，避免因频繁调用导致的费用或服务拒绝。
隔离生产和测试环境：确保测试与生产环境完全隔离，避免影响真实数据。
数据回滚和清理：在需要修改数据库或外部资源时，确保在测试后回滚或清理数据。
使用监控工具：监控资源使用情况，确保不会造成过度消耗。
通过这些方法，你可以确保自动化测试能够高效、低成本地执行，同时避免资源浪费或产生不必要的费用。
```

### 性能测试相关

#### 怎么选取性能测试点

- 选择核心业务模块(日志入库，事件入库)
- 选择并发量高的业务模块
- 选择有复杂数据库操作或者频繁磁盘读写的模块(版本升级)
- 资源消耗大的操作(报告生成、批处理、复杂的查询等)

#### 怎么评估性能是否达标，有哪些指标

```
1. 响应时间（Response Time）
定义：从用户请求发出到系统响应返回之间的时间。对于 Web 应用，通常指的是从用户点击链接或提交请求到页面完全加载的时间。
评估标准：
一般来说，响应时间应控制在 2秒以内，理想情况下，小于1秒 是最理想的。
高响应时间可能会影响用户体验和转化率。
可以设置不同级别的响应时间目标，例如：
正常负载下：响应时间应该满足 SLA（服务级别协议）的要求。
高负载/压力测试下：应保持响应时间在可接受范围内，可能会有小幅上升，但不能超过预定的最大值。
2. 吞吐量（Throughput）
定义：单位时间内系统处理的请求数量，通常以请求数/秒（RPS）或事务数/秒（TPS）表示。
评估标准：
根据业务需求，吞吐量应满足实际需求，比如高并发访问时是否能够处理高并发请求。
系统在高负载情况下，吞吐量的下降幅度应该是可接受的，不能急剧下降。
3. 并发用户数（Concurrent Users）
定义：系统能够同时处理的用户数量。
评估标准：
在指定的硬件和配置下，系统应该支持一定数量的并发用户，而不会导致崩溃或性能极度下降。
测试应评估系统在 预期并发量 和 极限并发量 下的表现。
根据业务需求，系统的并发支持数量可能有所不同，通常会依据最大并发用户数来确定是否达标。
4. 错误率（Error Rate）
定义：系统在负载下出现的错误请求占总请求的比率，通常以百分比表示。
评估标准：
错误率应尽量低，通常期望系统的错误率低于 1%。
错误率过高可能表示系统在高负载下出现崩溃、资源耗尽或其他问题。
5. 资源利用率（Resource Utilization）
定义：系统资源的使用情况，包括 CPU 使用率、内存使用率、磁盘 I/O、网络带宽等。
评估标准：
CPU 和内存使用率应保持在 合理范围，通常 CPU 使用率 不应长时间超过 80%-90%，以避免资源瓶颈。
内存的使用也应合理，避免内存泄漏或频繁的垃圾回收。
确保磁盘 I/O 和网络带宽足够，避免在高并发时出现资源饱和。
6. 系统稳定性（Stability）
定义：系统在高负载情况下的稳定性，是否能够在长时间负载下持续工作。
评估标准：
系统应能够承受长时间的高负载而不崩溃，通常要求 24小时内无宕机。
长时间负载测试可以帮助发现内存泄漏、资源耗尽等潜在问题。
7. 可扩展性（Scalability）
定义：系统在负载增加时，是否能够通过增加资源来保持或提升性能。
评估标准：
在负载增加时，系统应能够通过横向扩展（增加服务器数量）或纵向扩展（增强单台服务器配置）来处理更高的请求量。
可扩展性测试可以通过模拟并发增加来评估系统是否能够平稳扩展。
9. 峰值负载承载能力（Peak Load Handling）
定义：系统在最大负载下的表现，评估其在突然流量激增时的处理能力。
评估标准：
测试系统的负载承载能力，确保在流量高峰期不会崩溃或出现严重性能下降。
10. 响应时间分布（Response Time Distribution）
定义：响应时间的分布情况，查看在不同请求量下系统响应时间的变化。
评估标准：
需要查看 P90、P95 和 P99 响应时间，评估大多数用户请求的响应时间。如果 P95 或 P99 响应时间过高，可能表明系统存在性能瓶颈。
```



#### 新接口或者新功能在测试前怎么初步评估性能合理值

```
1. 分析业务需求和预期负载
功能重要性分析：首先了解新接口或功能的业务重要性，评估它是否是系统中的“关键路径”部分，或者是否有高并发访问的可能。
例如，如果是用户登录、支付、搜索等关键功能，它们可能需要更严格的性能要求。
如果是后台处理、数据导入等批处理类功能，可能对响应时间的要求较低，但吞吐量和稳定性更重要。
预期负载估算：结合业务需求，预估未来的负载。例如，预计每天有多少用户会访问此接口或功能，访问频率如何。
可以通过历史数据分析（如果有）或业务规划数据来估算日活跃用户数（DAU）、并发用户数、每用户的请求次数等。
参考竞争产品或类似功能的负载情况，进行初步的负载预估。
2. 参考现有系统的性能基准
如果是现有系统中新增的接口或功能，可以参考系统中类似接口或功能的性能数据，作为性能评估的起点。
例如，类似的查询接口、数据处理流程或外部服务调用的响应时间和吞吐量。
通过对比这些现有接口的性能，评估新接口功能可能的性能预期。
3. 进行规模化测试的容量预估
单用户性能评估：对于新功能或接口，首先进行小规模的单用户性能测试，获取其响应时间、处理时间等基本性能数据。
通过负载工具（如 JMeter、Gatling、LoadRunner 等）模拟单用户操作，评估请求响应时间、服务器端处理时间等。
并发用户评估：逐渐增加并发用户数，测试新接口或新功能在不同负载下的响应时间、吞吐量、错误率等指标。
预测并发用户数，可以基于业务估算的访问量来确定峰值负载（例如，高峰时段的最大并发请求数）。
4. 设定预期的性能目标
响应时间目标：根据新功能的性质，设定响应时间目标。例如：
如果是实时交互功能，响应时间通常需要控制在 1-2秒 内。
如果是后台批量数据处理，可能响应时间不那么敏感，但吞吐量可能是关键目标。
吞吐量目标：通过预估的访问量和业务需求来设定吞吐量目标。例如，预计每秒多少请求或事务。
可以参考系统的历史数据，或者估算最大可能的请求量来确定吞吐量。
5. 对比同类功能的性能指标
如果是类似于其他已有功能的接口或功能，可以参考类似接口的性能表现（例如，类似的查询接口或服务接口）。
比如，如果新功能是查询某种数据，可以参考现有数据查询接口的响应时间、吞吐量等性能指标。
如果是调用外部 API 的功能，可以通过参考其他外部接口的性能指标来设定合理的性能值。
```

#### 性能不达标时，应该怎么分析和定位

```
1. 确认问题现象
性能指标未达标：确定具体性能问题是什么，是响应时间过长、吞吐量不足、资源过度消耗、还是错误率过高等。
问题发生的时机：记录何时出现性能问题（例如，高峰时段、并发增加时、特定功能时等）。了解问题发生的时机有助于定位问题的根源。
2. 收集和分析性能数据
负载测试数据：收集并发用户数、响应时间、吞吐量、CPU/内存/磁盘使用率等数据。
检查负载测试的指标，如响应时间分布、吞吐量的变化、资源利用率。
日志分析：查看应用程序、数据库、服务器等的日志，寻找性能瓶颈或异常。
特别注意错误日志、超时日志、警告日志等。
性能监控工具：使用性能监控工具（如 Prometheus、Grafana、New Relic、AppDynamics、Dynatrace 等）获取实时监控数据，帮助识别潜在瓶颈。
3. 识别瓶颈类型
性能瓶颈可能存在于多个层面，下面列出了常见的瓶颈类型以及相应的分析方法：

CPU瓶颈：

表现：CPU利用率过高，导致系统无法处理更多请求。
定位方法：使用系统监控工具（如 top、htop、vmstat 等）查看 CPU 利用率。如果某个进程占用了大量 CPU，说明该进程可能是瓶颈。
优化方法：优化计算密集型任务、使用异步处理、增加多核支持、负载均衡等。
内存瓶颈：

表现：系统内存使用率过高，出现交换、垃圾回收频繁等现象。
定位方法：通过工具（如 free、vmstat、top 等）查看内存使用情况。如果出现内存泄漏或垃圾回收问题，可以通过 Java 的 jvmstat、Python 的 memory_profiler 等工具检查。
优化方法：优化内存使用，减少不必要的缓存，增加内存容量，修复内存泄漏。
磁盘I/O瓶颈：

表现：磁盘I/O利用率过高，导致读取/写入操作的延迟。
定位方法：使用 iostat、vmstat、dstat 等工具查看磁盘 I/O 状况，检查是否有磁盘操作频繁的进程。
优化方法：优化数据库索引、优化文件存储操作、增加磁盘带宽或分布式存储。
网络瓶颈：

表现：网络带宽或延迟过高，导致请求超时或响应缓慢。
定位方法：使用 ping、traceroute、netstat 等工具检查网络连接和延迟，检查网络接口的带宽使用情况。
优化方法：优化网络传输，增加带宽，压缩数据传输，使用 CDN 缓存。
数据库瓶颈：

表现：数据库响应时间过长，查询效率低，锁竞争严重。
定位方法：
使用数据库的 EXPLAIN、SHOW STATUS 或 Slow Query Log 等工具查看查询效率。
监控数据库连接池的状态、查询执行时间、锁情况等。
优化方法：
优化慢查询，增加索引，重构查询。
通过分库分表、读写分离等手段提升数据库性能。
增加数据库缓存，优化连接池设置。
应用程序瓶颈：

表现：应用逻辑繁重，导致响应时间过长或处理能力不足。
定位方法：使用应用性能监控工具（如 New Relic、Dynatrace）或日志分析工具，查看哪些请求消耗了大量资源。
优化方法：
代码优化，减少冗余计算，减少同步等待。
优化缓存使用，减少不必要的数据库查询。
外部服务瓶颈：

表现：调用外部 API 或服务时，响应时间过长，影响系统性能。
定位方法：查看外部服务的响应时间，如果依赖的外部服务是瓶颈，可以考虑增加调用的重试机制或超时设置，优化调用方式。
优化方法：
缓存外部服务的结果。
使用异步调用，避免同步等待外部服务响应。
增加服务的容错性和冗余。
4. 检查并发和负载条件
在高并发负载下，系统的瓶颈可能会更加明显。通过模拟不同的负载条件进行压力测试，查看系统在高负载下的性能变化。
监控并发请求时的响应时间、吞吐量、资源消耗等，查看是否存在某些操作随着负载增加而急剧恶化的现象。
5. 深入分析代码与架构
如果问题来自应用程序或服务，进行代码分析是必不可少的。检查：
数据库查询的效率，避免 N+1 查询、复杂查询等。
缓存机制，检查是否有不必要的缓存失效或缓存不命中的问题。
多线程/多进程处理，检查是否存在线程/进程竞争、死锁或线程池问题。
6. 逐步优化和调整
针对分析出来的瓶颈进行逐步优化，不同的优化手段可以包括：
数据库优化：增加索引、优化查询、分库分表等。
代码优化：减少计算复杂度、使用高效的算法等。
硬件资源调整：增加 CPU、内存、磁盘、带宽等资源。
架构优化：使用负载均衡、微服务架构、缓存优化等。
7. 验证优化效果
在每次优化后，进行重新的性能测试，验证是否改进了性能，且是否没有引入新的问题。
继续监控系统，确保优化效果是持续的，并且没有导致其他潜在问题。
8. 持续监控与预警
在问题定位和优化后，部署有效的 性能监控和预警机制，及时捕捉潜在的性能下降，提前做出反应。
```

### mysql相关

#### 怎么查看mysql的慢查询

```
1. 开启慢查询日志
首先，你需要确保 MySQL 已经开启了慢查询日志功能。如果没有开启，可以按照以下步骤进行配置。

修改 MySQL 配置文件
打开 MySQL 配置文件 my.cnf（在 Linux 系统上通常位于 /etc/mysql/my.cnf 或 /etc/my.cnf，在 Windows 上通常是 C:\ProgramData\MySQL\MySQL Server X.X\my.ini）。
添加或修改以下配置项：
ini
复制代码
[mysqld]
slow_query_log = 1            # 开启慢查询日志
slow_query_log_file = /var/log/mysql/mysql-slow.log  # 慢查询日志文件路径
long_query_time = 2           # 查询超过 2 秒的语句将被记录到慢查询日志中
log_queries_not_using_indexes = 1  # 记录不使用索引的查询
slow_query_log：设置为 1 开启慢查询日志。
slow_query_log_file：指定慢查询日志文件的路径，可以根据需要进行修改。
long_query_time：设置查询执行时间超过多少秒的查询将被记录。例如，long_query_time = 2 表示查询执行时间超过 2 秒的会被记录。
log_queries_not_using_indexes：记录那些没有使用索引的查询（对于分析和优化查询很有用）。
保存配置文件后，重启 MySQL 服务以使配置生效：
bash
复制代码
sudo systemctl restart mysql    # Ubuntu/Debian
sudo service mysqld restart     # CentOS/RHEL
或者通过 MySQL 客户端动态设置：

sql
复制代码
SET GLOBAL slow_query_log = 1;
SET GLOBAL slow_query_log_file = '/var/log/mysql/mysql-slow.log';
SET GLOBAL long_query_time = 2;
2. 查看慢查询日志文件
慢查询日志默认存储在配置文件中设置的路径。例如，如果你将 slow_query_log_file 设置为 /var/log/mysql/mysql-slow.log，你可以使用以下命令查看日志文件：

bash
复制代码
cat /var/log/mysql/mysql-slow.log
或者使用 tail 命令实时查看日志内容：

bash
复制代码
tail -f /var/log/mysql/mysql-slow.log
你会看到类似以下格式的日志条目：

sql
复制代码
# Time: 2023-11-28T15:30:05.564922Z
# User@Host: root[root] @ localhost []
# Query_time: 2.102372  Lock_time: 0.000058 Rows_sent: 10  Rows_examined: 1000
use mydatabase;
SET timestamp=1638117005;
SELECT * FROM users WHERE age > 30;
Time：查询执行的时间。
User@Host：执行查询的 MySQL 用户和主机。
Query_time：查询执行的时间（秒）。Query_time: 2.102372 表示查询耗时 2.1 秒。
Lock_time：查询锁定的时间，通常情况下这个值是较小的，如果锁时间较长，可能需要优化锁的使用。
Rows_sent：返回的行数。
Rows_examined：查询过程中扫描的行数。
Query：实际执行的查询语句。
3. 分析慢查询日志
分析慢查询日志时，可以关注以下几个方面：

查询执行时间：长时间执行的查询，特别是超过几秒钟的查询，可能是性能瓶颈的来源。
查询次数：如果某些查询频繁执行且时间较长，可能是需要优化的目标。
索引使用情况：如果某些查询没有使用索引，可以通过添加索引来优化查询性能。
4. 使用 mysqldumpslow 工具分析日志
MySQL 提供了一个工具 mysqldumpslow 来分析慢查询日志，并生成更易于理解的汇总报告。使用该工具可以帮助你识别最常见的慢查询。

bash
复制代码
mysqldumpslow /var/log/mysql/mysql-slow.log
该命令将输出一个汇总报告，按查询执行时间或查询次数排序。你可以使用不同的选项来控制输出格式，例如：

-t N：显示最耗时的前 N 条查询。
-s：指定排序方式，如按时间、查询次数、锁时间等排序。
例如，显示前 10 个最慢的查询：

bash
复制代码
mysqldumpslow -t 10 /var/log/mysql/mysql-slow.log
5. 使用 pt-query-digest 分析慢查询日志
如果你需要更详细和专业的慢查询日志分析，可以使用 Percona Toolkit 中的 pt-query-digest 工具。它可以帮助你从慢查询日志中提取出有意义的信息，如常见的慢查询、查询的详细分析、索引建议等。

安装 Percona Toolkit：

bash
复制代码
sudo apt-get install percona-toolkit    # Ubuntu/Debian
sudo yum install percona-toolkit        # CentOS/RHEL
使用 pt-query-digest 分析慢查询日志：

bash
复制代码
pt-query-digest /var/log/mysql/mysql-slow.log
该命令将输出一个详细的报告，显示慢查询的统计信息、常见查询、最慢的查询等。

6. 动态查看慢查询
如果你不想在配置文件中开启慢查询日志，可以通过 MySQL 的动态变量在运行时开启和查看慢查询：

开启慢查询日志：

sql
复制代码
SET GLOBAL slow_query_log = 1;
SET GLOBAL slow_query_log_file = '/path/to/slow-query.log';
SET GLOBAL long_query_time = 2;
查看慢查询日志：

sql
复制代码
SHOW VARIABLES LIKE 'slow_query_log%';
SHOW VARIABLES LIKE 'long_query_time';
7. 优化慢查询
当你识别出慢查询后，可以通过以下方法来优化：

添加索引：确保查询字段有合适的索引，尤其是 WHERE 子句、JOIN 和 ORDER BY 子句中的字段。
查询重构：通过优化 SQL 查询的写法，避免不必要的全表扫描。使用 EXPLAIN 语句查看查询执行计划，帮助分析是否可以优化。
使用缓存：对于高频访问的查询，可以使用缓存技术（如 Memcached 或 Redis）来减轻数据库压力。
分库分表：对于大数据量的表，考虑将表分区或分库，减少单个查询的扫描行数。
批量处理：对于大量数据的处理，考虑使用批量操作，避免一次性处理过多数据导致性能问题。
总结
开启慢查询日志：通过修改 MySQL 配置文件或动态设置，开启慢查询日志并指定阈值。
查看日志：使用 cat、tail 或其他日志分析工具查看慢查询日志。
分析日志：使用 mysqldumpslow 或 pt-query-digest 工具分析慢查询日志，识别慢查询和优化点。
优化查询：通过添加索引、优化 SQL 语句、使用缓存和其他手段来提高查询性能。
```

#### 执行一条sql语句，期间发生了什么

- 连接器：建立连接，管理连接、校验用户身份；
- 查询缓存：查询语句如果命中查询缓存则直接返回，否则继续往下执行。MySQL 8.0 已删除该模块；
- 解析 SQL，通过解析器对 SQL 查询语句进行词法分析、语法分析，然后构建语法树，方便后续模块读取表名、字段、语句类型；
- 执行 SQL：执行 SQL 共有三个阶段：
  - 预处理阶段：检查表或字段是否存在；将 select * 中的 * 符号扩展为表上的所有列。
  - 优化阶段：基于查询成本的考虑， 选择查询成本最小的执行计划；
  - 执行阶段：根据执行计划执行  SQL 查询语句，从存储引擎读取记录，返回给客户端；

#### 索引失效的情况

- 当我们使用左或者左右模糊匹配的时候，也就是like %x 或者 like %x%
- 当我们在查询条件中对索引列做了计算、函数、类型转换操作，这些情况下都会造成索引失效；
- 联合索引要能正确使用需要遵循最左匹配原则，也就是按照最左优先的方式进行索引的匹配，否则就会导致索引失效。
- 在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。

#### 怎么优化索引

- 前缀索引优化：使用某个字段中字符串的前几个字符建立索引减小索引字段大小，可以增加一个索引页中存储的索引值，有效提高索引的查询速度
- 覆盖索引优化：减小索引字段大小，可以增加一个索引页中存储的索引值，有效提高索引的查询速度
- 主键索引最好是自增的：防止页分裂
- 防止索引失效

#### 怎么查看索引是否被使用

- 使用explan 查看执行计划
- possible_keys 字段表示可能用到的索引
- key 字段表示实际用的索引，如果这一项为 NULL，说明没有使用索引；
- key_len 表示索引的长度；
- rows 表示扫描的数据行数。
- type 表示数据扫描类型，我们需要重点看这个,执行效率从低到高
  - All（全表扫描）；
  - index（全索引扫描）
  - range（索引范围扫描）；
  - ref（非唯一索引扫描）；
  - eq_ref（唯一索引扫描）；
  - const（结果只有一条的主键或唯一索引扫描）。
- extra：
  - Using filesort ：当查询语句中包含 group by 操作，而且无法利用索引完成排序操作的时候， 这时不得不选择相应的排序算法进行，甚至可能会通过文件排序，效率是很低的，所以要避免这种问题的出现。
  - Using temporary：使了用临时表保存中间结果，MySQL 在对查询结果排序时使用临时表，常见于排序 order by 和分组查询 group by。效率低，要避免这种问题的出现。
  - Using index：表明使用了索引
  - Extra 为 `Using index condition`，那么说明使用了索引下推的优化

#### 事务的特性ACID

- 原子性：一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节，而且事务在执行过程中发生错误，会被回滚到事务开始前的状态
- 一致性：是指事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态
- 隔离性：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致，因为多个事务同时使用相同的数据时，不会相互干扰，每个事务都有一个完整的数据空间，对其他并发事务是隔离的。
- 持久性：事务处理结束后，对数据的修改就是永久的

#### 怎么保存事务的ACID

- 持久性是通过 redo log （重做日志）来保证的；
- 原子性是通过 undo log（回滚日志） 来保证的；
- 隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的；
- 一致性则是通过持久性+原子性+隔离性来保证；

#### 乐观锁和悲观锁

```
在 MySQL 中，乐观锁和悲观锁是两种常见的锁机制，用来处理并发事务时的竞争问题。它们各自适用于不同的场景，并通过不同的策略来保证数据一致性和避免冲突。

1. 悲观锁（Pessimistic Locking）
悲观锁假设并发冲突是常见的，因此在访问数据时，它会认为其他事务会修改数据，所以会对数据进行加锁，直到事务完成。这种方式的特点是“悲观”，即总是认为会发生数据冲突。

MySQL 中的悲观锁实现：
FOR UPDATE：通常用于 SELECT 查询中，当查询结果用于更新时，使用 FOR UPDATE 来对选中的记录加锁，直到事务提交。
LOCK IN SHARE MODE：另一种悲观锁，用于 SELECT 查询中，限制其他事务对选中的记录进行修改，但允许其他事务读取。
示例：

sql
复制代码
-- 使用 FOR UPDATE 实现悲观锁
BEGIN;

SELECT * FROM products WHERE product_id = 1 FOR UPDATE;

-- 执行其他操作（如更新数据）

COMMIT;
这条 SQL 查询会加锁 product_id = 1 的记录，直到事务提交。其他事务如果尝试修改该记录，会被阻塞，直到当前事务完成。

特点：
阻塞：如果记录被加锁，其他事务无法访问这些数据，直到当前事务提交或回滚。
适用场景：适合高竞争、对数据一致性要求高的场景。
2. 乐观锁（Optimistic Locking）
乐观锁假设并发冲突是偶然的，因此它不会在一开始就加锁，而是让事务执行时尽量不加锁。在更新数据时，乐观锁会检查在事务执行期间数据是否发生了变化，如果数据没有变化，就可以安全地提交更新；如果数据发生变化，则会中断当前事务，要求用户重新操作。

乐观锁实现的方式：
乐观锁通常通过以下两种方式来实现：

版本号：通过为每条记录添加一个版本号字段，每次更新数据时，检查版本号是否与原来的一致。如果一致，则执行更新，否则说明数据已被修改，需要重新处理。
时间戳：类似于版本号，但通过记录数据的最后更新时间戳，来判断数据是否发生变化。
示例：

使用版本号实现乐观锁：

表结构：

sql
复制代码
CREATE TABLE products (
    product_id INT PRIMARY KEY,
    name VARCHAR(255),
    price DECIMAL(10, 2),
    version INT
);
更新操作：

sql
复制代码
-- 读取数据时获取版本号
SELECT * FROM products WHERE product_id = 1;

-- 在更新时检查版本号
UPDATE products
SET price = 20.00, version = version + 1
WHERE product_id = 1 AND version = <old_version>;
如果在 UPDATE 语句执行时，version 不一致，说明数据已经被其他事务修改，更新失败。

使用时间戳实现乐观锁：

表结构：

sql
复制代码
CREATE TABLE products (
    product_id INT PRIMARY KEY,
    name VARCHAR(255),
    price DECIMAL(10, 2),
    last_updated TIMESTAMP
);
更新操作：

sql
复制代码
-- 读取数据时获取 last_updated
SELECT * FROM products WHERE product_id = 1;

-- 更新时检查时间戳
UPDATE products
SET price = 20.00, last_updated = NOW()
WHERE product_id = 1 AND last_updated = <old_timestamp>;
如果 last_updated 不匹配，说明数据已被修改，更新会失败。

特点：
无阻塞：不会阻塞其他事务。只有在更新时，如果发现数据发生了变化，才会让用户知道冲突。
适用场景：适合数据冲突不频繁的场景，比如查询多、修改少的应用，或者用户操作较为独立的情况。
总结：
悲观锁：通过加锁来避免并发冲突，适用于高并发冲突的场景。
乐观锁：通过版本号或时间戳等方式来检查数据是否发生变化，适用于冲突较少的场景。
选择哪种锁机制，取决于应用的并发量、数据的访问模式以及对性能和一致性的要求。
```

### 网络相关

#### HTTP和TCP的区别

```
HTTP（Hypertext Transfer Protocol）和TCP（Transmission Control Protocol）是计算机网络中两个不同层级的协议，功能和作用有所不同：
1. 所属层级
HTTP：
位于应用层。
是一种用于通信的应用协议，专门为客户端（如浏览器）和服务器之间传输超文本（如HTML、JSON等）设计。
TCP：
位于传输层。
是一种面向连接的传输协议，负责提供可靠的数据传输服务。
2. 作用
HTTP：
定义了客户端与服务器之间如何交换数据。
提供了一套规则（如GET、POST、PUT等）来请求和发送数据。
TCP：
为数据传输提供底层支持。
负责分组（分段）传输数据，确保数据能准确无误地从一端传输到另一端。
3. 工作机制
HTTP：
基于请求-响应模式：
客户端发出请求，服务器处理并返回响应。
HTTP 1.0默认是无状态的，每次请求独立；HTTP 1.1及之后版本支持长连接（Keep-Alive）。
TCP：
三次握手建立连接：
在数据传输前，双方先确认可以通信。
数据按顺序传输：
确保数据包不丢失、不重复。
4. 数据可靠性
HTTP：
依赖于TCP提供的可靠性。
自身不负责数据校验和重传，而是通过TCP来保证数据传输的完整性。
TCP：
通过重传机制和数据校验保证数据可靠性。
5. 示例
HTTP：
客户端：GET /index.html HTTP/1.1
服务器：HTTP/1.1 200 OK，并返回网页内容。
TCP：
将HTTP请求/响应报文分为多个小包，分批次发送，接收方按顺序重组这些包。
总结关系
TCP是HTTP的基础：
HTTP需要通过TCP建立可靠的通信通道，才能传输数据。
HTTP是应用层协议，它依赖TCP传输层协议来完成底层的网络通信任务。
```

#### HTTP1.0/HTTP1.1/HTTP2.0的区别

```
HTTP/1.0
发布时间：1996年

特点：
单请求单连接：

每次发送 HTTP 请求时，都会建立一个 TCP 连接，请求完成后立即关闭。
这种方式的性能很低，因为每次建立和关闭连接都需要额外的时间（如三次握手和四次挥手）。
缺少持久连接：

没有Connection: keep-alive机制，因此无法重用连接。
无状态设计：

每个请求都是独立的，服务器无法记住客户端的状态。
缺少一些功能：

不支持 Host 字段（导致无法在同一个 IP 地址上运行多个网站）。
缺乏缓存控制机制和错误码的标准化支持。
HTTP/1.1
发布时间：1997年（成为主流）

改进：
持久连接（Persistent Connection）：

默认启用了Connection: keep-alive，使得一个 TCP 连接可以被多个 HTTP 请求复用。
减少了建立和关闭连接的开销。
支持管线化（Pipelining）：

在一个连接上可以同时发送多个请求，而不必等待上一个请求完成。
问题：由于响应的顺序必须与请求顺序一致，管线化容易受到阻塞（称为“队头阻塞”）的影响，因此应用不多。
Host 字段支持：

增加了 Host 字段，支持同一个 IP 地址上部署多个虚拟主机（域名解析）。
解决了共享主机的问题。
更完善的缓存控制：

增加了Cache-Control、ETag、If-Modified-Since、If-None-Match等机制，改进缓存效率。
分块传输（Chunked Transfer Encoding）：

支持分块传输，允许在不确定内容总大小时逐块发送数据。
支持范围请求（Range Requests）：

可以请求资源的部分内容（如视频流），通过 Range 头部实现断点续传。
状态码更加丰富：

增加了一些状态码（如 100 Continue）。
HTTP/2.0
发布时间：2015年

改进：
HTTP/2 是对 HTTP/1.1 的重大升级，它优化了性能，主要特点包括：

二进制协议：

HTTP/2 改用二进制帧（Binary Protocol）传输，而不是 HTTP/1.1 的文本协议。
解析更加高效，减少了错误和歧义。
多路复用（Multiplexing）：

在一个 TCP 连接中，可以并发发送多个 HTTP 请求和响应，而不受顺序限制。
彻底解决了 HTTP/1.1 中的“队头阻塞”（Head-of-Line Blocking）问题。
头部压缩（Header Compression）：

使用 HPACK 算法对 HTTP 头部进行压缩，减少了冗余数据（如重复的 Cookie）。
减少了带宽占用，提高了传输效率。
服务器推送（Server Push）：

服务器可以主动将资源推送到客户端，而不是等待客户端请求（如预加载 CSS、JS 文件）。
更高的安全性：

虽然 HTTP/2 不强制要求使用加密，但主流浏览器只支持基于 TLS 的 HTTP/2（即 HTTPS）。
更高效的连接利用：

一个 TCP 连接可以处理所有并发请求，减少了连接建立和管理的开销。
缺点：
HTTP/2 在 TCP 层的多路复用依然会受到 TCP 队头阻塞的影响（如果一个包丢失，整个 TCP 流都会等待重传）。
总结对比
特性	HTTP/1.0	HTTP/1.1	HTTP/2.0
协议类型	文本协议	文本协议	二进制协议
连接管理	每次请求建立新连接	持久连接（Keep-Alive）	单连接多路复用
性能	性能较低	性能有所提升	性能显著提高
队头阻塞	有	有	无（应用层），但 TCP 仍有
头部压缩	无	无	有（HPACK 算法）
服务器推送	不支持	不支持	支持
适用场景	初期 Web 使用	静态资源较多的普通网站	高并发、复杂页面或资源场景
```

#### HTTP和WebSocket的区别

```
WebSocket 是一种网络通信协议，旨在实现客户端与服务器之间的双向通信。它允许在单个TCP连接上，进行全双工（双向实时通信）的数据交换，而不需要每次都重新建立连接。WebSocket 协议主要应用于需要实时、低延迟数据传输的场景，如在线游戏、即时通讯、股票实时行情、多人协作等。

WebSocket 的特点
持久连接：

WebSocket 通过建立一个持久的连接，使客户端与服务器之间能够保持长期连接，而不需要每次通信都重新建立连接。
双向通信：

传统的 HTTP 协议是请求-响应模式，客户端发起请求，服务器响应；而 WebSocket 则是双向的，客户端和服务器都可以主动发送数据。
低延迟：

因为连接是持久的，且不需要每次都建立新的连接，所以数据可以实时地传输，减少了延迟。
减少带宽消耗：

一旦建立 WebSocket 连接，数据传输不需要携带 HTTP 协议的头信息，减少了数据量和带宽消耗。
WebSocket 的工作原理
建立连接：

WebSocket 使用 HTTP 协议发起一个握手请求来建立连接。客户端通过发送一个 Upgrade 请求，告诉服务器它希望使用 WebSocket 协议。
例子：

客户端：GET /chat HTTP/1.1 + Upgrade: websocket + Connection: Upgrade
服务器响应：HTTP/1.1 101 Switching Protocols，同意升级协议。
数据交换：

握手成功后，客户端与服务器之间通过 WebSocket 协议交换数据，双方可以随时向对方发送消息。数据传输采用二进制或文本格式，通常使用帧（frame）进行分段传输。
关闭连接：

连接可以由任何一方发起关闭。当某一方希望关闭连接时，它会发送一个关闭帧（close frame），然后另一方响应确认关闭。
WebSocket 与 HTTP 的区别
连接方式：

HTTP 是请求/响应模式，客户端发起请求，服务器响应。每次请求都需要重新建立连接。
WebSocket 是持久连接，客户端和服务器通过 WebSocket 协议保持持续的双向连接。
通信模式：

HTTP 是单向通信，客户端发起请求，服务器响应。
WebSocket 是双向通信，客户端和服务器都可以随时发送数据。
性能：

HTTP 每次请求都会有额外的头部信息，且每次请求都要重新建立连接，可能导致性能开销较大。
WebSocket 建立连接后，不再有额外的开销，数据传输效率更高。
WebSocket 的应用场景
实时消息传递：

例如即时通讯应用（如微信、Slack）中，用户之间的消息传递需要实时、快速响应。
在线游戏：

多人在线游戏需要进行实时数据交换，WebSocket 提供了低延迟、高频率的数据传输。
金融应用：

股票、外汇等实时行情监控，WebSocket 可以实时推送价格变动数据，提供及时的信息。
协作应用：

如 Google Docs、Office 365 等多人在线协作编辑的应用，WebSocket 使得多人实时同步数据成为可能。
物联网（IoT）：

WebSocket 适合用于设备与服务器之间的实时通信，尤其在需要频繁、低延迟数据交换的 IoT 场景中。
WebSocket 的优点
实时性强：数据能够即时推送到客户端，无需等待轮询。
节省带宽：持久连接避免了每次建立连接的额外开销。
低延迟：无须建立新连接，数据能够快速传递。
双向通信：客户端和服务器都可以主动发送数据。
WebSocket 的缺点
浏览器支持问题：虽然现在大多数现代浏览器都支持 WebSocket，但旧版浏览器或某些特殊环境下可能不支持。
无加密：WebSocket 本身不提供加密，但可以通过 wss://（WebSocket Secure）来保证数据传输的安全性。
可能会遭遇防火墙问题：某些防火墙或代理服务器可能会阻止 WebSocket 连接。
WebSocket 与其他协议比较
与 HTTP：
WebSocket 适用于实时通信，而 HTTP 更适合一次性请求-响应的场景。
与 MQTT：
MQTT 也是一种轻量级的消息传输协议，适用于物联网等低带宽环境。WebSocket 更加通用，支持更复杂的应用场景。
总结
WebSocket 协议提供了一种高效、实时的双向通信方式，特别适用于实时应用、即时消息传递、在线游戏等场景。通过保持长连接，WebSocket 在减少延迟、降低带宽消耗和支持双向通信方面，优于传统的 HTTP 协议。
```

#### url输入浏览器中间的过程

- 对URL进行解析，解析出协议、对应的服务器和资源所在位置，生成HTTP请求
- DNS解析，获取真实的主机IP
  - 先查询本地浏览器缓存、操作系统缓存或者本地的hosts文件
  - 查询本地的DNS服务器
  - 查询根域名服务器->顶级域名服务器->权威域名服务器
- 添加TCP头部，通过TCP3次握手建立连接，并且TCP会保证数据在两个不同进程之间的可靠传输
- 添加IP头部，通过查询路由表，以及网络中的路由器设备，完成数据在两台不同主机之间的传输
- 通过arp协议，获取下一跳的mac地址，并添加帧头和帧尾，完成数据在同一网络中两个设备之间的数据传输
- 到达目的主机后，进行解封装，去掉帧头帧尾、IP头部、TCP头部，处理HTTP响应，并返回对应的数据
- 响应经过上述流程后，回到客户端，浏览器解析并展示对应的页面
- 通过TCP4次挥手，断开连接

### 测试相关

#### 怎么定位慢接口

#### 同步和异步的概念

```
**同步**和**异步**是编程中处理任务执行方式的两种基本模式，常用于描述多个任务或操作之间的执行顺序和相互依赖关系。

### 1. **同步（Synchronous）**
在同步操作中，任务按顺序执行，必须等待当前任务完成后，才能执行下一个任务。换句话说，一个任务的执行必须依赖于前一个任务的结果。

- **特点**：
  - **顺序执行**：任务一个接一个地按顺序执行，当前任务完成之前，后续任务不能开始。
  - **阻塞**：当前任务的执行会阻塞程序的其他任务，直到它完成。
  - **简单直观**：因为任务按顺序执行，程序的控制流非常清晰。

- **例子**：
  1. 程序先请求一个接口，等接口返回数据后，程序才进行下一步处理。
  2. 在传统的文件读取中，程序会等待文件读取完成后，再进行下一步操作。

### 2. **异步（Asynchronous）**
在异步操作中，任务可以在等待某些操作完成的同时，执行其他任务。当一个任务不需要等待另一个任务完成时，它会立即返回并允许其他操作继续执行。异步操作通常不会阻塞程序的执行流。

- **特点**：
  - **并发执行**：任务可以并行或交替进行，不需要等待上一个任务完成。
  - **非阻塞**：一个任务的执行不会阻塞程序的其他任务，可以让其他任务继续执行。
  - **需要回调或事件循环**：异步编程通常需要一个回调机制或事件循环来处理任务的完成通知。

- **例子**：
  1. 程序可以发起多个网络请求，并在所有请求完成时进行数据处理。
  2. 程序可以在文件读取过程中执行其他操作，读取完成后再处理文件内容。

### 3. **同步与异步的对比**

| **特点**           | **同步**                              | **异步**                             |
|-------------------|-------------------------------------|------------------------------------|
| **执行顺序**       | 任务按顺序执行，逐个完成                  | 任务可以同时执行，不需要等待前一个任务完成 |
| **阻塞/非阻塞**     | 阻塞，当前任务执行完才能继续执行下一个任务 | 非阻塞，任务可以交替进行            |
| **适用场景**       | 适合任务依赖性强，顺序执行的情况            | 适合并发任务，IO密集型操作（如网络请求、文件读写） |
| **实现复杂度**     | 相对简单，易于理解                     | 较复杂，需要回调、事件循环或线程池等机制 |
| **性能**           | 执行效率低，尤其在有IO操作时                 | 提高并发性能，减少等待时间         |

### 4. **同步与异步在不同场景的使用**
- **同步**：在一些任务需要严格按顺序执行时（如：金融系统的事务处理、数据库操作），同步可能更适合。
- **异步**：在需要处理大量并发操作或耗时的IO操作时（如：网络请求、数据库查询、大规模文件读取），异步编程可以显著提高性能和响应速度。

### 5. **同步与异步在网络请求中的应用**
- **同步请求**：客户端请求服务器数据时，客户端需要等待服务器返回响应，才继续执行后续操作。比如浏览器发送同步HTTP请求，直到获取到响应才继续加载页面内容。
- **异步请求**：在Web开发中，使用异步HTTP请求（如 AJAX）时，浏览器可以在等待服务器响应的同时继续其他操作，比如用户可以在等待数据时与页面交互。

### 总结
- **同步**：任务按顺序执行，每个任务必须等待前一个任务完成。
- **异步**：任务可以同时进行，当前任务不需要等待其他任务的完成，从而提升程序效率，尤其适用于IO密集型操作。

通过理解同步与异步的基本概念，能够帮助开发者根据具体的需求，选择合适的任务处理方式。
```

#### 什么是幂等测试

```
等幂测试（Idempotence Testing）是一种软件测试方法，用于验证系统在执行某个操作多次时，是否能够保持相同的状态或结果。简单来说，等幂性的核心是无论某个操作被执行一次还是多次，系统的最终状态应保持一致。

等幂的定义
一个操作是等幂的，当多次执行该操作对系统的状态或输出结果没有额外的影响。
常见的数学形式：
scss
复制代码
f(f(x)) = f(x)
即，函数 f 无论调用多少次，结果都是一致的。
等幂性在软件中的意义
在软件中，等幂性通常用来确保系统的稳定性，特别是在网络传输可能失败、重试机制存在的情况下。

典型场景
RESTful API

根据 HTTP 协议规范：
GET、PUT、DELETE 应是等幂的。
POST 通常不是等幂的。
例如：
调用 GET /users/1 多次，返回的结果始终相同。
调用 DELETE /users/1 多次，用户只会被删除一次。
数据库操作

如果某个操作被多次重复执行，数据库的最终状态应该是一样的。
例如：更新某条记录为固定的值，而不是基于已有值进行递增或变化。
支付系统

重复发送扣款请求，不应导致用户被多次扣款。
系统需要通过等幂机制，例如请求唯一 ID，确保相同请求只处理一次。
等幂测试的目标
验证等幂性： 确保操作重复执行时不会产生不一致的结果。
检测幂等缺陷： 检查因重试机制或意外操作导致的状态不一致。
提高系统可靠性： 避免因操作重试引发的问题，特别是在分布式系统中。
等幂测试方法
确定性操作验证

对于操作多次执行后，检查系统状态是否一致。
示例：
多次发送 PUT /users/1 { "name": "John" }，确保用户数据没有重复更新。
对比前后状态

初始状态 → 执行操作一次 → 执行多次 → 验证状态是否一致。
示例：
执行 DELETE /items/1 多次，确保 item 已删除，且无额外副作用。
模拟失败与重试

模拟网络重试，确保重复的请求不会造成错误。
示例：
模拟支付系统的扣款请求被重试多次，确保用户只被扣款一次。
日志验证

检查系统日志，确保重复操作没有引发多余的行为或副作用。
等幂测试的常见问题
非幂等操作的幂等化：
通过添加机制（如请求 ID、唯一性校验）让非幂等操作具备幂等性。
示例：为支付操作引入唯一事务号，确保同一事务只处理一次。
隐藏的副作用：
某些操作可能表面上看是幂等的，但会在系统中引发隐性问题。
示例：日志重复写入或触发下游任务等。
总结
等幂测试是确保系统在执行重复操作时具有稳定性和可靠性的重要测试方法，尤其在支持重试机制的系统（如分布式系统、网络 API）中更为关键。
```

#### 测试用例设计注意点

- 注意校验数据库中的内容
- 对于部分重要请求，如支付相关，注意幂等测试
- 注意边界值和数据类型

#### 黑盒测试设计方法

- 等价类划分
- 边界值分析
- 因果图法
- 判定表法
- 场景法
- 异常猜测法&错误推断法
- 状态迁移图法&流程分析法

#### 白盒测试设计方法

- 语句覆盖
- 判定覆盖
- 条件覆盖
- 路径覆盖
- 基本路径覆盖

#### 测试影响范围怎么评估

- 理解改动的内容，确定直接影响区域、间接影响内容，上下游模块等
- 在平时需要整理出某个模块依赖哪些东西，确定改动某个东西时的影响返回

#### 没有覆盖到的线上问题怎么处理

- 分析根因，并复现问题
- 快速修复问题
- 补充对应的测试用例
- 分析测试未覆盖的原因，是否可以作为典型用户场景补充到测试设计模板中

#### 需求从上线到发布的过程

- 参与需求评审
- 初步评估测试工作量
- 参加开发人员的测试评审
- 进行测试设计，编写测试用例
- 待开发完成并进行UT后，进行一个冒烟测试
- 进行分支测试，主线测试，主线回归，以及一个为期一周的黄金周测试
- 版本发布

#### 遇到缺陷比较多的情况怎么办

- 确保需求主要功能完成测试，测试时标记一下严重或者阻塞的bug，让开发早点解决并给出一个解决日期
- 测试过程中遇到风险及时上报风险，及时确定是否增加人力或者延期交付
- 测试被阻塞过程中，编写部分核心的接口测试自动化脚本，待bug被修改后，及时运行自动化脚本，避免衰退

#### 缺陷比较多但是又想要急着发布怎么办

- 确保测试case已全部执行，功能已经覆盖到
- 确定重要级别的bug已经全部修改
- 运行自动化脚本，确保没有引入衰退问题
- 若以上有不满足，但是要是要求发布，表明自己的态度，不赞同发布，但是尽力在发布前做好测试工作







## 其他问题

#### 自我介绍

面试官你好，我叫喻顺，21年毕业河海大学通信工程专业，从毕业到现在一直工作与于苏州的山石网科，主要负责的产品是山石智源的测试工作，因为是公司的一个小产品线，大概10来个测试人员，所以负责的测试内容没有分的那么细，主要是某几个模块的功能测试，性能测试；因为公司的产品是软件硬件一起卖的，但是也有专门提供软件的情况，所以也负责公司的软件版本在虚拟平台上的一个测试，除了手工测试以外，还负责产品的自动化测试，包括webui的自动化和接口的自动化，并且负责产品线的和公司测试平台的对接。使用的编程语言主要是python

#### 团队冲突

1. 看prd，产品经理
2. 找领导

#### 职业规划



#### 为什么换城市



#### 换行业有什么考虑



#### 印象比较深的项目/比较困难的时刻

刚入职一年时的单人负责资产模块重构后的测试

1. 模块比较核心，之前从来没有接触过这个模块
2. 影响范围大，和其他业务的关联太多，考虑不全，且测试时间评估不到位
3. bug很多，且开发人员没有一次改好bug，导致bug需要反复验证
4. 流程不合理，有时候开发会在一个bug里面改多个问题



https://xiaolincoding.com/mysql/index/index_interview.html#%E7%B4%A2%E5%BC%95%E7%9A%84%E5%88%86%E7%B1%BB