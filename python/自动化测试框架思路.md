# 自动化测试框架编写思路

通过读取yaml文件的内容，提取yaml文件中的关键字，根据关键字来对于对应的value进行操作
通过反射机制hasattr，来判断关键字对应什么操作，如variables、validate等



#### 怎么修改pytest中的脚本执行顺序

- 默认按照文件名称的排序顺序执行，在文件中按照定义的顺序进行执行的
- 可以使用pytest的插件，pytest-order
- 通过pytest的钩子pytest_collection_modifyitems
- @pytest.mark 标记，并在运行时使用命令行指定某些组的顺序



#### 怎么实现多个脚本同一个预配置

- 通过pytest的钩子pytest_collection_modifyitems
- 使用@pytest.mark 标记，对脚本进行分组



#### fixture怎么实现setup和teardown功能

- yield
- 可以通过 `scope` 参数调整 `fixture` 的生命周期



#### 为什么要自己写一套基于yaml文件的接口测试框架，和公司的框架有什么区别

1. yaml文件编写更简单，但是没有那么灵活，如果加功能可能需要修改框架
2. 公司python脚本的方时更灵活，而且公司框架需要同时支持ui，cli，接口测试
3. 练手，以及学习jenkins docker



#### 什么是fixture

```
fixture 是 pytest 中的一个重要概念，用来为测试提供初始化数据和清理操作。它是一个函数，可以在测试运行前准备必要的资源（如数据库连接、文件、网络连接等），并在测试完成后执行清理操作（如关闭连接、删除临时文件等）。fixture 允许测试函数或类复用这些资源，避免重复的代码，并保证测试的独立性和隔离性。

fixture 的特点
自动管理资源：在测试之前自动创建资源，测试完成后自动销毁资源。
支持共享资源：多个测试用例可以共享同一个 fixture 资源。
灵活性：可以指定作用域、自动清理等功能。
```



#### 怎么修改pytest匹配文件的规则

```
通过在 pytest.ini 文件中添加自定义的 python_files 和 python_functions 配置项，你可以修改 pytest 收集测试的文件和函数匹配模式。
命令行选项 --python-files 和 --python-functions
你还可以通过命令行选项动态修改收集规则：
```



#### 自动化测试过程中可能会有一些资源损耗的问题，应该怎么处理，比如支付接口等

```
在自动化测试中，处理资源消耗问题（尤其是像支付接口这样可能涉及到实际费用的服务）时，可以采取以下策略：

使用 Mock 技术：通过模拟支付接口的响应，避免实际调用支付接口。
使用沙箱或测试环境：许多外部服务提供沙箱环境，可以模拟实际操作而不产生费用。
实现限流和重试机制：在多次调用外部服务时，避免因频繁调用导致的费用或服务拒绝。
隔离生产和测试环境：确保测试与生产环境完全隔离，避免影响真实数据。
数据回滚和清理：在需要修改数据库或外部资源时，确保在测试后回滚或清理数据。
使用监控工具：监控资源使用情况，确保不会造成过度消耗。
通过这些方法，你可以确保自动化测试能够高效、低成本地执行，同时避免资源浪费或产生不必要的费用。
```

#### 怎么选取性能测试点

- 选择核心业务模块(日志入库，事件入库)
- 选择并发量高的业务模块
- 选择有复杂数据库操作或者频繁磁盘读写的模块(版本升级)
- 资源消耗大的操作(报告生成、批处理、复杂的查询等)

#### 怎么评估性能是否达标，有哪些指标

```
1. 响应时间（Response Time）
定义：从用户请求发出到系统响应返回之间的时间。对于 Web 应用，通常指的是从用户点击链接或提交请求到页面完全加载的时间。
评估标准：
一般来说，响应时间应控制在 2秒以内，理想情况下，小于1秒 是最理想的。
高响应时间可能会影响用户体验和转化率。
可以设置不同级别的响应时间目标，例如：
正常负载下：响应时间应该满足 SLA（服务级别协议）的要求。
高负载/压力测试下：应保持响应时间在可接受范围内，可能会有小幅上升，但不能超过预定的最大值。
2. 吞吐量（Throughput）
定义：单位时间内系统处理的请求数量，通常以请求数/秒（RPS）或事务数/秒（TPS）表示。
评估标准：
根据业务需求，吞吐量应满足实际需求，比如高并发访问时是否能够处理高并发请求。
系统在高负载情况下，吞吐量的下降幅度应该是可接受的，不能急剧下降。
3. 并发用户数（Concurrent Users）
定义：系统能够同时处理的用户数量。
评估标准：
在指定的硬件和配置下，系统应该支持一定数量的并发用户，而不会导致崩溃或性能极度下降。
测试应评估系统在 预期并发量 和 极限并发量 下的表现。
根据业务需求，系统的并发支持数量可能有所不同，通常会依据最大并发用户数来确定是否达标。
4. 错误率（Error Rate）
定义：系统在负载下出现的错误请求占总请求的比率，通常以百分比表示。
评估标准：
错误率应尽量低，通常期望系统的错误率低于 1%。
错误率过高可能表示系统在高负载下出现崩溃、资源耗尽或其他问题。
5. 资源利用率（Resource Utilization）
定义：系统资源的使用情况，包括 CPU 使用率、内存使用率、磁盘 I/O、网络带宽等。
评估标准：
CPU 和内存使用率应保持在 合理范围，通常 CPU 使用率 不应长时间超过 80%-90%，以避免资源瓶颈。
内存的使用也应合理，避免内存泄漏或频繁的垃圾回收。
确保磁盘 I/O 和网络带宽足够，避免在高并发时出现资源饱和。
6. 系统稳定性（Stability）
定义：系统在高负载情况下的稳定性，是否能够在长时间负载下持续工作。
评估标准：
系统应能够承受长时间的高负载而不崩溃，通常要求 24小时内无宕机。
长时间负载测试可以帮助发现内存泄漏、资源耗尽等潜在问题。
7. 可扩展性（Scalability）
定义：系统在负载增加时，是否能够通过增加资源来保持或提升性能。
评估标准：
在负载增加时，系统应能够通过横向扩展（增加服务器数量）或纵向扩展（增强单台服务器配置）来处理更高的请求量。
可扩展性测试可以通过模拟并发增加来评估系统是否能够平稳扩展。
9. 峰值负载承载能力（Peak Load Handling）
定义：系统在最大负载下的表现，评估其在突然流量激增时的处理能力。
评估标准：
测试系统的负载承载能力，确保在流量高峰期不会崩溃或出现严重性能下降。
10. 响应时间分布（Response Time Distribution）
定义：响应时间的分布情况，查看在不同请求量下系统响应时间的变化。
评估标准：
需要查看 P90、P95 和 P99 响应时间，评估大多数用户请求的响应时间。如果 P95 或 P99 响应时间过高，可能表明系统存在性能瓶颈。
```



#### 新接口或者新功能在测试前怎么初步评估性能合理值

```
1. 分析业务需求和预期负载
功能重要性分析：首先了解新接口或功能的业务重要性，评估它是否是系统中的“关键路径”部分，或者是否有高并发访问的可能。
例如，如果是用户登录、支付、搜索等关键功能，它们可能需要更严格的性能要求。
如果是后台处理、数据导入等批处理类功能，可能对响应时间的要求较低，但吞吐量和稳定性更重要。
预期负载估算：结合业务需求，预估未来的负载。例如，预计每天有多少用户会访问此接口或功能，访问频率如何。
可以通过历史数据分析（如果有）或业务规划数据来估算日活跃用户数（DAU）、并发用户数、每用户的请求次数等。
参考竞争产品或类似功能的负载情况，进行初步的负载预估。
2. 参考现有系统的性能基准
如果是现有系统中新增的接口或功能，可以参考系统中类似接口或功能的性能数据，作为性能评估的起点。
例如，类似的查询接口、数据处理流程或外部服务调用的响应时间和吞吐量。
通过对比这些现有接口的性能，评估新接口功能可能的性能预期。
3. 进行规模化测试的容量预估
单用户性能评估：对于新功能或接口，首先进行小规模的单用户性能测试，获取其响应时间、处理时间等基本性能数据。
通过负载工具（如 JMeter、Gatling、LoadRunner 等）模拟单用户操作，评估请求响应时间、服务器端处理时间等。
并发用户评估：逐渐增加并发用户数，测试新接口或新功能在不同负载下的响应时间、吞吐量、错误率等指标。
预测并发用户数，可以基于业务估算的访问量来确定峰值负载（例如，高峰时段的最大并发请求数）。
4. 设定预期的性能目标
响应时间目标：根据新功能的性质，设定响应时间目标。例如：
如果是实时交互功能，响应时间通常需要控制在 1-2秒 内。
如果是后台批量数据处理，可能响应时间不那么敏感，但吞吐量可能是关键目标。
吞吐量目标：通过预估的访问量和业务需求来设定吞吐量目标。例如，预计每秒多少请求或事务。
可以参考系统的历史数据，或者估算最大可能的请求量来确定吞吐量。
5. 对比同类功能的性能指标
如果是类似于其他已有功能的接口或功能，可以参考类似接口的性能表现（例如，类似的查询接口或服务接口）。
比如，如果新功能是查询某种数据，可以参考现有数据查询接口的响应时间、吞吐量等性能指标。
如果是调用外部 API 的功能，可以通过参考其他外部接口的性能指标来设定合理的性能值。
```

#### 性能不达标时，应该怎么分析和定位

```
1. 确认问题现象
性能指标未达标：确定具体性能问题是什么，是响应时间过长、吞吐量不足、资源过度消耗、还是错误率过高等。
问题发生的时机：记录何时出现性能问题（例如，高峰时段、并发增加时、特定功能时等）。了解问题发生的时机有助于定位问题的根源。
2. 收集和分析性能数据
负载测试数据：收集并发用户数、响应时间、吞吐量、CPU/内存/磁盘使用率等数据。
检查负载测试的指标，如响应时间分布、吞吐量的变化、资源利用率。
日志分析：查看应用程序、数据库、服务器等的日志，寻找性能瓶颈或异常。
特别注意错误日志、超时日志、警告日志等。
性能监控工具：使用性能监控工具（如 Prometheus、Grafana、New Relic、AppDynamics、Dynatrace 等）获取实时监控数据，帮助识别潜在瓶颈。
3. 识别瓶颈类型
性能瓶颈可能存在于多个层面，下面列出了常见的瓶颈类型以及相应的分析方法：

CPU瓶颈：

表现：CPU利用率过高，导致系统无法处理更多请求。
定位方法：使用系统监控工具（如 top、htop、vmstat 等）查看 CPU 利用率。如果某个进程占用了大量 CPU，说明该进程可能是瓶颈。
优化方法：优化计算密集型任务、使用异步处理、增加多核支持、负载均衡等。
内存瓶颈：

表现：系统内存使用率过高，出现交换、垃圾回收频繁等现象。
定位方法：通过工具（如 free、vmstat、top 等）查看内存使用情况。如果出现内存泄漏或垃圾回收问题，可以通过 Java 的 jvmstat、Python 的 memory_profiler 等工具检查。
优化方法：优化内存使用，减少不必要的缓存，增加内存容量，修复内存泄漏。
磁盘I/O瓶颈：

表现：磁盘I/O利用率过高，导致读取/写入操作的延迟。
定位方法：使用 iostat、vmstat、dstat 等工具查看磁盘 I/O 状况，检查是否有磁盘操作频繁的进程。
优化方法：优化数据库索引、优化文件存储操作、增加磁盘带宽或分布式存储。
网络瓶颈：

表现：网络带宽或延迟过高，导致请求超时或响应缓慢。
定位方法：使用 ping、traceroute、netstat 等工具检查网络连接和延迟，检查网络接口的带宽使用情况。
优化方法：优化网络传输，增加带宽，压缩数据传输，使用 CDN 缓存。
数据库瓶颈：

表现：数据库响应时间过长，查询效率低，锁竞争严重。
定位方法：
使用数据库的 EXPLAIN、SHOW STATUS 或 Slow Query Log 等工具查看查询效率。
监控数据库连接池的状态、查询执行时间、锁情况等。
优化方法：
优化慢查询，增加索引，重构查询。
通过分库分表、读写分离等手段提升数据库性能。
增加数据库缓存，优化连接池设置。
应用程序瓶颈：

表现：应用逻辑繁重，导致响应时间过长或处理能力不足。
定位方法：使用应用性能监控工具（如 New Relic、Dynatrace）或日志分析工具，查看哪些请求消耗了大量资源。
优化方法：
代码优化，减少冗余计算，减少同步等待。
优化缓存使用，减少不必要的数据库查询。
外部服务瓶颈：

表现：调用外部 API 或服务时，响应时间过长，影响系统性能。
定位方法：查看外部服务的响应时间，如果依赖的外部服务是瓶颈，可以考虑增加调用的重试机制或超时设置，优化调用方式。
优化方法：
缓存外部服务的结果。
使用异步调用，避免同步等待外部服务响应。
增加服务的容错性和冗余。
4. 检查并发和负载条件
在高并发负载下，系统的瓶颈可能会更加明显。通过模拟不同的负载条件进行压力测试，查看系统在高负载下的性能变化。
监控并发请求时的响应时间、吞吐量、资源消耗等，查看是否存在某些操作随着负载增加而急剧恶化的现象。
5. 深入分析代码与架构
如果问题来自应用程序或服务，进行代码分析是必不可少的。检查：
数据库查询的效率，避免 N+1 查询、复杂查询等。
缓存机制，检查是否有不必要的缓存失效或缓存不命中的问题。
多线程/多进程处理，检查是否存在线程/进程竞争、死锁或线程池问题。
6. 逐步优化和调整
针对分析出来的瓶颈进行逐步优化，不同的优化手段可以包括：
数据库优化：增加索引、优化查询、分库分表等。
代码优化：减少计算复杂度、使用高效的算法等。
硬件资源调整：增加 CPU、内存、磁盘、带宽等资源。
架构优化：使用负载均衡、微服务架构、缓存优化等。
7. 验证优化效果
在每次优化后，进行重新的性能测试，验证是否改进了性能，且是否没有引入新的问题。
继续监控系统，确保优化效果是持续的，并且没有导致其他潜在问题。
8. 持续监控与预警
在问题定位和优化后，部署有效的 性能监控和预警机制，及时捕捉潜在的性能下降，提前做出反应。
```





## 其他问题

#### 为什么换城市



#### 换行业有什么考虑



#### 印象比较深的项目/比较困难的时刻

刚入职一年时的单人负责资产模块重构后的测试

1. 模块比较核心，之前从来没有接触过这个模块
2. 影响范围大，和其他业务的关联太多，考虑不全，且测试时间评估不到位
3. bug很多，且开发人员没有一次改好bug，导致bug需要反复验证
4. 流程不合理，有时候开发会在一个bug里面改多个问题